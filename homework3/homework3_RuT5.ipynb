{
 "cells": [
  {
   "metadata": {
    "id": "kSIGLID31Cr7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746446531908,
     "user_tz": -180,
     "elapsed": 44,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T17:47:26.413049Z",
     "start_time": "2025-05-05T17:47:26.405708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ],
   "id": "dd5107192de4aaad",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "id": "uBk5uQ4k1CsG",
    "outputId": "554d7918-6709-4a19-a08d-e62cff682a48",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746446699698,
     "user_tz": -180,
     "elapsed": 155279,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T17:47:39.634457Z",
     "start_time": "2025-05-05T17:47:27.839672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Установка необходимых библиотек:\n",
    "!pip install scikit-learn\n",
    "!pip install numpy\n",
    "!pip install datasets\n",
    "!pip install pandas\n",
    "!pip install transformers[torch]\n",
    "!pip install razdel\n",
    "!pip install evaluate"
   ],
   "id": "9eef1c630805404f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: scikit-learn in /home/alexandr/miniconda3/lib/python3.12/site-packages (1.6.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.5)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: numpy in /home/alexandr/miniconda3/lib/python3.12/site-packages (2.2.5)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: datasets in /home/alexandr/miniconda3/lib/python3.12/site-packages (3.5.1)\r\n",
      "Requirement already satisfied: filelock in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.5)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: aiohttp in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.18)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (0.30.2)\r\n",
      "Requirement already satisfied: packaging in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: pandas in /home/alexandr/miniconda3/lib/python3.12/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas) (2.2.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: transformers[torch] in /home/alexandr/miniconda3/lib/python3.12/site-packages (4.51.3)\r\n",
      "Requirement already satisfied: filelock in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (2.2.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=2.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (2.7.0)\r\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from transformers[torch]) (1.6.0)\r\n",
      "Requirement already satisfied: psutil in /home/alexandr/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\r\n",
      "Requirement already satisfied: setuptools in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (72.1.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (9.5.1.17)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (0.6.3)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (2.26.2)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (2025.4.26)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0->transformers[torch]) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Requirement already satisfied: razdel in /home/alexandr/miniconda3/lib/python3.12/site-packages (0.5.0)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (3.5.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (2.2.5)\r\n",
      "Requirement already satisfied: dill in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (0.30.2)\r\n",
      "Requirement already satisfied: packaging in /home/alexandr/miniconda3/lib/python3.12/site-packages (from evaluate) (24.1)\r\n",
      "Requirement already satisfied: filelock in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.11.18)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2025.4.26)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/alexandr/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "Installing collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.3\r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jZ271nOXVU9v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447127175,
     "user_tz": -180,
     "elapsed": 38,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T17:48:04.386843Z",
     "start_time": "2025-05-05T17:48:04.287237Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datasets import Dataset, DatasetDict\n",
    "from evaluate import load\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "import torch\n",
    "from functools import partial\n",
    "from razdel import tokenize"
   ],
   "id": "123c5ef5021649f6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Фиксирование рандома, чтобы результат был более менее воспроизводим\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "\n",
    "seed_all(1234)"
   ],
   "metadata": {
    "id": "PMzk9PxOMqHs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746446790305,
     "user_tz": -180,
     "elapsed": 101,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T17:48:11.758893Z",
     "start_time": "2025-05-05T17:48:11.748741Z"
    }
   },
   "id": "f6bdf89e33e711a6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MTV04hmHouT-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447242621,
     "user_tz": -180,
     "elapsed": 48,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T17:48:19.048274Z",
     "start_time": "2025-05-05T17:48:18.989196Z"
    }
   },
   "source": [
    "# Загрузка данных\n",
    "BASE_DIR = \"/home/alexandr/PycharmProjects/NLP_homework/homework3\"\n",
    "data = pd.read_csv(\"in_domain_train.csv\", usecols=['sentence', 'acceptable'])\n",
    "test_data = pd.read_csv(\"in_domain_dev.csv\")\n",
    "test_data = test_data[['sentence', 'acceptable']]\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "train_data = train_data.reset_index()[['sentence', 'acceptable']]\n",
    "val_data = val_data.reset_index()[['sentence', 'acceptable']]"
   ],
   "id": "925018d9d323013c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUECLA1WF56d"
   },
   "source": [
    "# Новый раздел"
   ],
   "id": "a1219647f0dd654e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1746434405694,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     },
     "user_tz": -180
    },
    "id": "rQvhjBW-wqwR",
    "outputId": "67dee3c5-f5cb-41f4-a833-5b3f7c3bbe0a",
    "ExecuteTime": {
     "end_time": "2025-05-05T16:54:04.895423Z",
     "start_time": "2025-05-05T16:54:04.882026Z"
    }
   },
   "source": [
    "train_data"
   ],
   "id": "a705cf96ff9ea7f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               sentence  acceptable\n",
       "0               Приближался нечеловеческие рев и топот.           0\n",
       "1     В котором часу завтра утром начинается конфере...           1\n",
       "2                   Она сидела на диване рядом с мужем.           1\n",
       "3     Это были студенты, сами сведущие в эскимосском...           1\n",
       "4     При всем том я оптимист и думаю, что мой конфл...           1\n",
       "...                                                 ...         ...\n",
       "6290  Она хочет поговорить с каким-нибудь хорошим сп...           1\n",
       "6291  При расставании я целовал три раза чудесные, с...           1\n",
       "6292  Парк в старом русле реки Турии, раскинувшиеся ...           0\n",
       "6293  Страны НАТО хотят взять с Ирана обязательство ...           0\n",
       "6294  Едва Степан Трофимович остановился и приглядел...           0\n",
       "\n",
       "[6295 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Приближался нечеловеческие рев и топот.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В котором часу завтра утром начинается конфере...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Она сидела на диване рядом с мужем.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Это были студенты, сами сведущие в эскимосском...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>При всем том я оптимист и думаю, что мой конфл...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>Она хочет поговорить с каким-нибудь хорошим сп...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>При расставании я целовал три раза чудесные, с...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>Парк в старом русле реки Турии, раскинувшиеся ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>Страны НАТО хотят взять с Ирана обязательство ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>Едва Степан Трофимович остановился и приглядел...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6295 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 6309,
     "status": "ok",
     "timestamp": 1746447142278,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     },
     "user_tz": -180
    },
    "id": "K4mHB04565mz",
    "ExecuteTime": {
     "end_time": "2025-05-05T18:34:17.741318Z",
     "start_time": "2025-05-05T18:11:02.365733Z"
    }
   },
   "source": [
    "# Загружаем нужную модель\n",
    "model_checkpoint = \"sberbank-ai/ruT5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint, num_labels=2)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    model = model.to(\"cuda\")"
   ],
   "id": "c4eb27c0c3ccf28b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:  50%|####9     | 1.47G/2.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e326fcaa8abc45c39f2421456cf6c53f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57cb67b35d4d46b2ba385216ff7a6fa2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b32286f3ebd54ef09e9445625e320b86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8a879c82c014738af106fdfdb13bdc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# Функция обработки\n",
    "def preprocess_examples(examples, tokenizer):\n",
    "    result = tokenizer(examples[\"sentence\"], padding=False)\n",
    "\n",
    "    if \"acceptable\" in examples:\n",
    "        label_sequences = []\n",
    "        for label in examples[\"acceptable\"]:\n",
    "            if label in [0, 1]:\n",
    "                target_sequence = str(label)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown class label\")\n",
    "            label_sequences.append(target_sequence)\n",
    "\n",
    "    else:\n",
    "        # a hack to avoid the \"You have to specify either decoder_input_ids or decoder_inputs_embeds\" error\n",
    "        # for test data\n",
    "        label_sequences = [\"\" for _ in examples[\"sentence\"]]\n",
    "\n",
    "    result[\"labels\"] = tokenizer(label_sequences, padding=False)[\"input_ids\"]\n",
    "    result[\"length\"] = [len(list(tokenize(sentence))) for sentence in examples[\"sentence\"]]\n",
    "    return result"
   ],
   "metadata": {
    "id": "j97lVdli3feQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447145647,
     "user_tz": -180,
     "elapsed": 12,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T18:34:58.404198Z",
     "start_time": "2025-05-05T18:34:58.396708Z"
    }
   },
   "id": "ca1a2a58a1cca688",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vaJ_meMM8X9Y",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "5145169b4dea4e288768f1734de4ed64",
      "b0a7d3f569e84773926c00f0a7909720",
      "06fe444b7b8c474fa7eb19bea866d499",
      "b84536dfd02449409c4177c90baa59e0",
      "edf219077c5b45dca3ed970e5a85225e",
      "1a257615ec5c4ce4b57db9b87c3cf16c",
      "d993f8fa5dea42f6b5b25a18ece0f377",
      "7c433e32fe5a4cd792a219404c26a9a3",
      "d7ac4a47bcba4dfab8cb897da243774f",
      "e8364a257e72432c80ba052eb2528c67",
      "ebcd53f4ab814261a9c6fd7cc56eeeca",
      "bb78fe3296554aa3852491cc538e40c4",
      "fbb27a27918049d98dddb7e89944a2ab",
      "7bce20acefb343899893cbb6f9279a08",
      "09ffb6acf8f64c04a4606b36ec9e8dac",
      "0d9ce94250c34d37a7e6428f4291084b",
      "22db009dc58845f88e62599dd5134b86",
      "0c166149796741ddb8a281d47a5ef242",
      "717939ee14794130a3631f7806479ce9",
      "389822ab292e407f97bf77dfaa1fc82f",
      "8feeab83c76e4cdc8f03e7ca3241c74e",
      "c26629a7160946cfb13b67fe5356b9a6",
      "39c2e70f46914e0d80d2c5f7b4db149c",
      "a6c0825659254364bf33055f48ce80b7",
      "e774ea85cb534a7b9f9e12bcd54efd56",
      "41838afe34444d21b803cc9b903acf99",
      "7a46842553624888a41313cb05cca0a6",
      "0f3c652c5c1a41fd96c2d41d2f273b74",
      "08a3ac5214824cd5838749ed0ea79c9f",
      "6c9ef60d41a04a12b3f7cb1a1c4e05c7",
      "24b1c88ee3b7414cb1362189c7a80af8",
      "c3ef5939a9ed46c7b8e48d77a08844ee",
      "8aabea2129a74e379ab9a4e5975dfead"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447152853,
     "user_tz": -180,
     "elapsed": 2317,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "outputId": "6969576d-1922-4118-c14f-c8c8faf142a1",
    "ExecuteTime": {
     "end_time": "2025-05-05T18:35:03.723407Z",
     "start_time": "2025-05-05T18:35:01.659449Z"
    }
   },
   "source": [
    "\n",
    "train, val, test = map(Dataset.from_pandas, (train_data, val_data, test_data))\n",
    "data = DatasetDict(train=train, val=val, test=test)\n",
    "tokenized_dataset = data.map(\n",
    "    partial(preprocess_examples, tokenizer=tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=[\"sentence\"],\n",
    ")"
   ],
   "id": "cdfbaccf14ba9de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/6295 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3687be9372cd4c1dbf64c7f9380a2b17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1574 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb910f8f5c29447aa6f1e56c0a89db20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/983 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea60d7fd03574cd7b69424f84a0237cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SoYd5d5VKzKE",
    "ExecuteTime": {
     "end_time": "2025-05-03T11:32:56.258323Z",
     "start_time": "2025-05-03T11:32:56.254218Z"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447319909,
     "user_tz": -180,
     "elapsed": 54,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    }
   },
   "source": [
    "# Функция для расчета метрики\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    print(labels)\n",
    "    print(pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ],
   "outputs": [],
   "execution_count": 18,
   "id": "4da646de782393e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T18:35:11.841516Z",
     "start_time": "2025-05-05T18:35:08.578578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ACCURACY = load(\"accuracy\", keep_in_memory=True)\n",
    "MCC = load(\"matthews_correlation\", keep_in_memory=True)\n",
    "\n",
    "# Функция для расчета метрики\n",
    "def compute_metrics(p, tokenizer):\n",
    "    string_preds = tokenizer.batch_decode(p.predictions, skip_special_tokens=True)\n",
    "    int_preds = [int(prediction) for prediction in string_preds]\n",
    "\n",
    "    labels = np.where(p.label_ids != -100, p.label_ids, tokenizer.pad_token_id)\n",
    "    string_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    int_labels = []\n",
    "\n",
    "    for string_label in string_labels:\n",
    "        if string_label in [0, 1]:\n",
    "            int_labels.append(int(string_label))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    acc_result = ACCURACY.compute(predictions=int_preds, references=int_labels)\n",
    "    mcc_result = MCC.compute(predictions=int_preds, references=int_labels)\n",
    "\n",
    "    result = {\"accuracy\": acc_result[\"accuracy\"], \"mcc\": mcc_result[\"matthews_correlation\"]}\n",
    "\n",
    "    return result"
   ],
   "id": "d637e8f54c5814c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad76baeda2704a34802d76cb4e9f2c66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.60k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2e02ce8662c41c7b17cc7bd45926138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bpMa2CQ48YAH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447323679,
     "user_tz": -180,
     "elapsed": 36,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T19:10:32.005212Z",
     "start_time": "2025-05-05T19:10:31.997184Z"
    }
   },
   "source": [
    "# Параметры, которые будут использоваться для обучения\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./fine-tuning_RuT5_results',  #Выходной каталог\n",
    "    num_train_epochs=3,  #Кол-во эпох для обучения\n",
    "    per_device_train_batch_size=16,  #Размер пакета для каждого устройства во время обучения\n",
    "    per_device_eval_batch_size=8,  #Размер пакета для каждого устройства во время валидации\n",
    "    weight_decay=5e-2,  #Понижение весов\n",
    "    load_best_model_at_end=True,  #Загружать ли лучшую модель после обучения\n",
    "    learning_rate=2e-5,  #Скорость обучения\n",
    "    eval_strategy='epoch',  #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
    "    logging_strategy='epoch',  #Логирование после каждой эпохи\n",
    "    save_strategy='epoch',  #Сохранение после каждой эпохи\n",
    "    gradient_accumulation_steps=16,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    group_by_length=True,\n",
    "    report_to=\"none\",\n",
    "    metric_for_best_model=\"eval_mcc\",\n",
    "    optim=\"adafactor\",\n",
    "    predict_with_generate=True,\n",
    ")"
   ],
   "id": "e8fac66a2821c910",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "id": "lTK7n-BT1Csu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1746447331337,
     "user_tz": -180,
     "elapsed": 4805,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T19:10:34.588076Z",
     "start_time": "2025-05-05T19:10:34.566417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    "trainer = Seq2SeqTrainer(model=model,\n",
    "                         args=training_args,\n",
    "                         train_dataset=tokenized_dataset['train'],\n",
    "                         eval_dataset=tokenized_dataset['val'],\n",
    "                         compute_metrics=compute_metrics,\n",
    "                         data_collator=data_collator,\n",
    "                         )"
   ],
   "id": "fa4fbc0277d9e234",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "id": "2N31peiR1Csw",
    "outputId": "6ea616ae-eeec-4d77-d57d-e51a4e2624bb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1746447706903,
     "user_tz": -180,
     "elapsed": 128,
     "user": {
      "displayName": "Александр Горбенко",
      "userId": "06688681954453153232"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-05-05T19:07:53.810605Z",
     "start_time": "2025-05-05T19:01:22.423656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "id": "6fe8bedee19ae18d",
   "outputs": [
    {
     "ename": "InductorError",
     "evalue": "CppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp -D TORCH_INDUCTOR_CPP_WRAPPER -D STANDALONE_TORCH_HEADER -D C10_USING_CUSTOM_GENERATED_MACROS -D CPU_CAPABILITY_AVX2 -shared -fPIC -O3 -DNDEBUG -fno-trapping-math -funsafe-math-optimizations -ffinite-math-only -fno-signed-zeros -fno-math-errno -fexcess-precision=fast -fno-finite-math-only -fno-unsafe-math-optimizations -ffp-contract=off -fno-tree-loop-vectorize -march=native -Wall -std=c++17 -Wno-unused-variable -Wno-unknown-pragmas -fopenmp -I/home/alexandr/miniconda3/include/python3.12 -I/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/include -I/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -mavx2 -mfma -mf16c -D_GLIBCXX_USE_CXX11_ABI=1 -ltorch -ltorch_cpu -ltorch_python -lgomp -L/home/alexandr/miniconda3/lib -L/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/lib -o /tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.so\n\nOutput:\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp: In function 'void kernel(const int64_t*, const float*, const float*, const float*, const float*, const float*, const float*, float*, float*)':\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp:29:23: error: redeclaration of 'float tmp_acc0_arr [8]'\n   29 |                 float tmp_acc0_arr[8];\n      |                       ^~~~~~~~~~~~\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp:17:23: note: 'float tmp_acc0_arr [8]' previously declared here\n   17 |                 float tmp_acc0_arr[8];\n      |                       ^~~~~~~~~~~~\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInductorError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m trainer.train()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[32m   2246\u001B[39m         args=args,\n\u001B[32m   2247\u001B[39m         resume_from_checkpoint=resume_from_checkpoint,\n\u001B[32m   2248\u001B[39m         trial=trial,\n\u001B[32m   2249\u001B[39m         ignore_keys_for_eval=ignore_keys_for_eval,\n\u001B[32m   2250\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2560\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2553\u001B[39m context = (\n\u001B[32m   2554\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2555\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2556\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2557\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2558\u001B[39m )\n\u001B[32m   2559\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2560\u001B[39m     tr_loss_step = \u001B[38;5;28mself\u001B[39m.training_step(model, inputs, num_items_in_batch)\n\u001B[32m   2562\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2563\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2564\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2565\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2566\u001B[39m ):\n\u001B[32m   2567\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2568\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:3782\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   3779\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   3780\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3782\u001B[39m \u001B[38;5;28mself\u001B[39m.accelerator.backward(loss, **kwargs)\n\u001B[32m   3784\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:2454\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2452\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2453\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2454\u001B[39m     loss.backward(**kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m torch.autograd.backward(\n\u001B[32m    649\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    650\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m _engine_run_backward(\n\u001B[32m    354\u001B[39m     tensors,\n\u001B[32m    355\u001B[39m     grad_tensors_,\n\u001B[32m    356\u001B[39m     retain_graph,\n\u001B[32m    357\u001B[39m     create_graph,\n\u001B[32m    358\u001B[39m     inputs,\n\u001B[32m    359\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    360\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    361\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    825\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    826\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/function.py:307\u001B[39m, in \u001B[36mBackwardCFunction.apply\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    301\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    302\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mImplementing both \u001B[39m\u001B[33m'\u001B[39m\u001B[33mbackward\u001B[39m\u001B[33m'\u001B[39m\u001B[33m and \u001B[39m\u001B[33m'\u001B[39m\u001B[33mvjp\u001B[39m\u001B[33m'\u001B[39m\u001B[33m for a custom \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    303\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFunction is not allowed. You should only implement one \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    304\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mof them.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    305\u001B[39m     )\n\u001B[32m    306\u001B[39m user_fn = vjp_fn \u001B[38;5;28;01mif\u001B[39;00m vjp_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Function.vjp \u001B[38;5;28;01melse\u001B[39;00m backward_fn\n\u001B[32m--> \u001B[39m\u001B[32m307\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m user_fn(\u001B[38;5;28mself\u001B[39m, *args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2111\u001B[39m, in \u001B[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward\u001B[39m\u001B[34m(ctx, *flat_args)\u001B[39m\n\u001B[32m   2109\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m CompiledFunction._double_backward(ctx, impl_fn, all_args)\n\u001B[32m   2110\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m impl_fn()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2097\u001B[39m, in \u001B[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward.<locals>.impl_fn\u001B[39m\u001B[34m(double_ctx)\u001B[39m\n\u001B[32m   2096\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mimpl_fn\u001B[39m(double_ctx=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m2097\u001B[39m     out = CompiledFunction._backward_impl(ctx, all_args)\n\u001B[32m   2098\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _backward_epilogue_functional(\n\u001B[32m   2099\u001B[39m         CompiledFunction.metadata,\n\u001B[32m   2100\u001B[39m         CompiledFunction.maybe_subclass_metadata,\n\u001B[32m   2101\u001B[39m         out,\n\u001B[32m   2102\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:2186\u001B[39m, in \u001B[36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction._backward_impl\u001B[39m\u001B[34m(ctx, all_args)\u001B[39m\n\u001B[32m   2175\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m tracing(saved_context), compile_context(\n\u001B[32m   2176\u001B[39m     saved_compile_context\n\u001B[32m   2177\u001B[39m ), context(), track_graph_compiling(\n\u001B[32m   (...)\u001B[39m\u001B[32m   2183\u001B[39m     dynamo_compile_column_us=\u001B[33m\"\u001B[39m\u001B[33mbackward_cumulative_compile_time_us\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2184\u001B[39m ):\n\u001B[32m   2185\u001B[39m     CompileEventLogger.compilation_metric(is_forward=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m2186\u001B[39m     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n\u001B[32m   2187\u001B[39m         bw_module, placeholder_list\n\u001B[32m   2188\u001B[39m     )\n\u001B[32m   2189\u001B[39m     \u001B[38;5;66;03m# Maybe save cache entry\u001B[39;00m\n\u001B[32m   2190\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m try_save_cache_entry \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2191\u001B[39m         \u001B[38;5;66;03m# CompiledFunction.metadata\u001B[39;00m\n\u001B[32m   2192\u001B[39m         \u001B[38;5;66;03m# CompiledFunction.maybe_subclass_metadata\u001B[39;00m\n\u001B[32m   2193\u001B[39m         \u001B[38;5;66;03m# bw_module\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:479\u001B[39m, in \u001B[36mSerializableAOTDispatchCompiler.__call__\u001B[39m\u001B[34m(self, gm, example_inputs)\u001B[39m\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\n\u001B[32m    475\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    476\u001B[39m     gm: torch.fx.GraphModule,\n\u001B[32m    477\u001B[39m     example_inputs: Sequence[InputType],\n\u001B[32m    478\u001B[39m ) -> OutputCode:\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.compiler_fn(gm, example_inputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:72\u001B[39m, in \u001B[36mAotAutograd.__call__.<locals>.wrap_bw_compiler.<locals>._wrapped_bw_compiler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_wrapped_bw_compiler\u001B[39m(*args, **kwargs):\n\u001B[32m     71\u001B[39m     \u001B[38;5;66;03m# stop TorchDynamo from trying to compile our generated backwards pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m disable(disable(bw_compiler_fn)(*args, **kwargs))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001B[39m, in \u001B[36mDisableContext.__call__.<locals>._fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    836\u001B[39m _maybe_set_eval_frame(_callback_from_stance(\u001B[38;5;28mself\u001B[39m.callback))\n\u001B[32m    837\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m838\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(*args, **kwargs)\n\u001B[32m    839\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    840\u001B[39m     set_eval_frame(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_utils_internal.py:97\u001B[39m, in \u001B[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     94\u001B[39m \u001B[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001B[39;00m\n\u001B[32m     95\u001B[39m \u001B[38;5;66;03m# in stack traces when profiling is not enabled.\u001B[39;00m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001B[32m---> \u001B[39m\u001B[32m97\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m function(*args, **kwargs)\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001B[32m    100\u001B[39m     function, phase_name, *args, **kwargs\n\u001B[32m    101\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:2014\u001B[39m, in \u001B[36mcompile_fx.<locals>.bw_compiler\u001B[39m\u001B[34m(gm, example_inputs)\u001B[39m\n\u001B[32m   2008\u001B[39m fixed = count_tangents(gm)\n\u001B[32m   2009\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[32m   2010\u001B[39m     config.patch(get_cpp_wrapper_config())\n\u001B[32m   2011\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m config.cpp_wrapper\n\u001B[32m   2012\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext()\n\u001B[32m   2013\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m2014\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_compile(\n\u001B[32m   2015\u001B[39m         gm,\n\u001B[32m   2016\u001B[39m         example_inputs,\n\u001B[32m   2017\u001B[39m         static_input_idxs=\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(fixed)),\n\u001B[32m   2018\u001B[39m         cudagraphs=cudagraphs,\n\u001B[32m   2019\u001B[39m         is_backward=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m   2020\u001B[39m         graph_id=graph_id,\n\u001B[32m   2021\u001B[39m         boxed_forward_device_index=forward_device,\n\u001B[32m   2022\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:628\u001B[39m, in \u001B[36mcompile_fx_inner\u001B[39m\u001B[34m(gm, example_inputs, **kwargs)\u001B[39m\n\u001B[32m    623\u001B[39m stack.enter_context(DebugContext())\n\u001B[32m    624\u001B[39m CompileEventLogger.pt2_compile(\n\u001B[32m    625\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33minductor_compile\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    626\u001B[39m     is_backward=kwargs[\u001B[33m\"\u001B[39m\u001B[33mis_backward\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m    627\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m628\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_compiler_debug(_compile_fx_inner, compiler_name=\u001B[33m\"\u001B[39m\u001B[33minductor\u001B[39m\u001B[33m\"\u001B[39m)(\n\u001B[32m    629\u001B[39m     gm,\n\u001B[32m    630\u001B[39m     example_inputs,\n\u001B[32m    631\u001B[39m     **kwargs,\n\u001B[32m    632\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:124\u001B[39m, in \u001B[36mwrap_compiler_debug.<locals>.debug_wrapper\u001B[39m\u001B[34m(gm, example_inputs, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m config.repro_after \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33mdynamo\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33maot\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    121\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    122\u001B[39m     \u001B[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001B[39;00m\n\u001B[32m    123\u001B[39m     \u001B[38;5;66;03m# with fake inputs\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m     inner_compiled_fn = compiler_fn(gm, example_inputs)\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    126\u001B[39m     \u001B[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001B[39;00m\n\u001B[32m    127\u001B[39m     \u001B[38;5;66;03m# need a different serialization strategy\u001B[39;00m\n\u001B[32m    128\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m config.repro_after == \u001B[33m\"\u001B[39m\u001B[33maot\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:760\u001B[39m, in \u001B[36m_compile_fx_inner\u001B[39m\u001B[34m(gm, example_inputs, **graph_kwargs)\u001B[39m\n\u001B[32m    758\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m    759\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m--> \u001B[39m\u001B[32m760\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m InductorError(e, currentframe()).with_traceback(\n\u001B[32m    761\u001B[39m         e.__traceback__\n\u001B[32m    762\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    763\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    764\u001B[39m     TritonBundler.end_compile()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:745\u001B[39m, in \u001B[36m_compile_fx_inner\u001B[39m\u001B[34m(gm, example_inputs, **graph_kwargs)\u001B[39m\n\u001B[32m    743\u001B[39m TritonBundler.begin_compile()\n\u001B[32m    744\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m745\u001B[39m     mb_compiled_graph = fx_codegen_and_compile(\n\u001B[32m    746\u001B[39m         gm, example_inputs, inputs_to_check, **graph_kwargs\n\u001B[32m    747\u001B[39m     )\n\u001B[32m    748\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m mb_compiled_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    749\u001B[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1295\u001B[39m, in \u001B[36mfx_codegen_and_compile\u001B[39m\u001B[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001B[39m\n\u001B[32m   1291\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcompile_fx_subproc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _SubprocessFxCompile\n\u001B[32m   1293\u001B[39m     scheme = _SubprocessFxCompile()\n\u001B[32m-> \u001B[39m\u001B[32m1295\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1197\u001B[39m, in \u001B[36m_InProcessFxCompile.codegen_and_compile\u001B[39m\u001B[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001B[39m\n\u001B[32m   1184\u001B[39m             compiled_fn = AotCodeCompiler.compile(\n\u001B[32m   1185\u001B[39m                 graph,\n\u001B[32m   1186\u001B[39m                 wrapper_code.value,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1194\u001B[39m                 ],\n\u001B[32m   1195\u001B[39m             )\n\u001B[32m   1196\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1197\u001B[39m         compiled_fn = graph.compile_to_module().call\n\u001B[32m   1199\u001B[39m num_bytes, nodes_num_elem, node_runtimes = graph.count_bytes()\n\u001B[32m   1200\u001B[39m metrics.num_bytes_accessed += num_bytes\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/graph.py:2083\u001B[39m, in \u001B[36mGraphLowering.compile_to_module\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2076\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompile_to_module\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> ModuleType:\n\u001B[32m   2077\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[32m   2078\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mGraphLowering.compile_to_module\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2079\u001B[39m         phase_name=\u001B[33m\"\u001B[39m\u001B[33mcode_gen\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2080\u001B[39m         log_pt2_compile_event=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m   2081\u001B[39m         dynamo_compile_column_us=\u001B[33m\"\u001B[39m\u001B[33minductor_code_gen_cumulative_compile_time_us\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2082\u001B[39m     ):\n\u001B[32m-> \u001B[39m\u001B[32m2083\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compile_to_module()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/graph.py:2130\u001B[39m, in \u001B[36mGraphLowering._compile_to_module\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2124\u001B[39m     trace_structured(\n\u001B[32m   2125\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33minductor_output_code\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2126\u001B[39m         \u001B[38;5;28;01mlambda\u001B[39;00m: {\u001B[33m\"\u001B[39m\u001B[33mfilename\u001B[39m\u001B[33m\"\u001B[39m: path},\n\u001B[32m   2127\u001B[39m         payload_fn=\u001B[38;5;28;01mlambda\u001B[39;00m: wrapper_code.value,\n\u001B[32m   2128\u001B[39m     )\n\u001B[32m   2129\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[33m\"\u001B[39m\u001B[33mPyCodeCache.load_by_key_path\u001B[39m\u001B[33m\"\u001B[39m, log_pt2_compile_event=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m2130\u001B[39m     mod = PyCodeCache.load_by_key_path(\n\u001B[32m   2131\u001B[39m         key,\n\u001B[32m   2132\u001B[39m         path,\n\u001B[32m   2133\u001B[39m         linemap=linemap,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[32m   2134\u001B[39m         attrs={**\u001B[38;5;28mself\u001B[39m.constants, **\u001B[38;5;28mself\u001B[39m.torchbind_constants},\n\u001B[32m   2135\u001B[39m     )\n\u001B[32m   2136\u001B[39m \u001B[38;5;28mself\u001B[39m.cache_key = key\n\u001B[32m   2137\u001B[39m \u001B[38;5;28mself\u001B[39m.cache_path = path\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/codecache.py:2747\u001B[39m, in \u001B[36mPyCodeCache.load_by_key_path\u001B[39m\u001B[34m(cls, key, path, linemap, attrs)\u001B[39m\n\u001B[32m   2744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m linemap \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2745\u001B[39m     linemap = []\n\u001B[32m-> \u001B[39m\u001B[32m2747\u001B[39m mod = _reload_python_module(key, path)\n\u001B[32m   2749\u001B[39m \u001B[38;5;66;03m# unzip into separate lines/nodes lists\u001B[39;00m\n\u001B[32m   2750\u001B[39m \u001B[38;5;28mcls\u001B[39m.linemaps[path] = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*linemap))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/runtime/compile_tasks.py:36\u001B[39m, in \u001B[36m_reload_python_module\u001B[39m\u001B[34m(key, path)\u001B[39m\n\u001B[32m     34\u001B[39m mod.\u001B[34m__file__\u001B[39m = path\n\u001B[32m     35\u001B[39m mod.key = key  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m exec(code, mod.\u001B[34m__dict__\u001B[39m, mod.\u001B[34m__dict__\u001B[39m)\n\u001B[32m     37\u001B[39m sys.modules[mod.\u001B[34m__name__\u001B[39m] = mod\n\u001B[32m     38\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m mod\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/torchinductor_alexandr/cs/ccstzemwe366myo5kti2fxdbyllks4ydwhhlfg2q7me2fuyvzfz4.py:205\u001B[39m\n\u001B[32m     31\u001B[39m cpp_fused__log_softmax_backward_data_add_nll_loss_backward_nll_loss_forward_0 = async_compile.cpp_pybinding([\u001B[33m'\u001B[39m\u001B[33mconst int64_t*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mconst float*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mfloat*\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mfloat*\u001B[39m\u001B[33m'\u001B[39m], \u001B[33m'''\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[33m#include \u001B[39m\u001B[33m\"\u001B[39m\u001B[33m/tmp/torchinductor_alexandr/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[33mextern \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mC\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  void kernel(const int64_t* in_ptr0,\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    173\u001B[39m \u001B[33m}\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[33m'''\u001B[39m)\n\u001B[32m    177\u001B[39m cpp_fused_mul_1 = async_compile.cpp_pybinding([\u001B[33m'\u001B[39m\u001B[33mfloat*\u001B[39m\u001B[33m'\u001B[39m], \u001B[33m'''\u001B[39m\n\u001B[32m    178\u001B[39m \u001B[33m#include \u001B[39m\u001B[33m\"\u001B[39m\u001B[33m/tmp/torchinductor_alexandr/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    179\u001B[39m \u001B[33mextern \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mC\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  void kernel(float* in_out_ptr0)\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    201\u001B[39m \u001B[33m}\u001B[39m\n\u001B[32m    202\u001B[39m \u001B[33m'''\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m205\u001B[39m async_compile.wait(\u001B[38;5;28mglobals\u001B[39m())\n\u001B[32m    206\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m async_compile\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall\u001B[39m(args):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/async_compile.py:424\u001B[39m, in \u001B[36mAsyncCompile.wait\u001B[39m\u001B[34m(self, scope)\u001B[39m\n\u001B[32m    417\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m get_compile_threads() > \u001B[32m1\u001B[39m:\n\u001B[32m    418\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\n\u001B[32m    419\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33masync_compile.wait\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    420\u001B[39m         log_pt2_compile_event=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    421\u001B[39m         dynamo_compile_column_us=\u001B[33m\"\u001B[39m\u001B[33mtriton_compile_time_us\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    422\u001B[39m         log_waitcounter=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    423\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m424\u001B[39m         \u001B[38;5;28mself\u001B[39m._wait_futures(scope)\n\u001B[32m    426\u001B[39m _compile_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/async_compile.py:445\u001B[39m, in \u001B[36mAsyncCompile._wait_futures\u001B[39m\u001B[34m(self, scope)\u001B[39m\n\u001B[32m    443\u001B[39m     pbar.set_postfix_str(key)\n\u001B[32m    444\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m     scope[key] = result.result()\n\u001B[32m    446\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m BrokenProcessPool \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    448\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mA compilation subprocess exited unexpectedly. This \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    449\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mis likely due to a crash. To facilitate debugging, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    450\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can re-run with TORCHINDUCTOR_COMPILE_THREADS=1 \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    451\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mto cause compilation to occur in the main process.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    452\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/codecache.py:3224\u001B[39m, in \u001B[36mLambdaFuture.result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   3223\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Callable[..., Any]:  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3224\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.result_fn()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/codecache.py:2242\u001B[39m, in \u001B[36mCppPythonBindingsCodeCache.load_pybinding_async.<locals>.future\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m   2240\u001B[39m \u001B[38;5;28;01mnonlocal\u001B[39;00m result\n\u001B[32m   2241\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2242\u001B[39m     result = get_result()\n\u001B[32m   2243\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, ModuleType)\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(result, \u001B[38;5;28mcls\u001B[39m.entry_function)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/codecache.py:2050\u001B[39m, in \u001B[36mCppCodeCache.load_async.<locals>.load_fn\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m   2048\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m lib \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2049\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m future \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2050\u001B[39m         future.result()\n\u001B[32m   2051\u001B[39m     result = worker_fn()\n\u001B[32m   2052\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/concurrent/futures/_base.py:456\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    454\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    455\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__get_result()\n\u001B[32m    457\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    458\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/concurrent/futures/thread.py:58\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     55\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m58\u001B[39m     result = \u001B[38;5;28mself\u001B[39m.fn(*\u001B[38;5;28mself\u001B[39m.args, **\u001B[38;5;28mself\u001B[39m.kwargs)\n\u001B[32m     59\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     60\u001B[39m     \u001B[38;5;28mself\u001B[39m.future.set_exception(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/codecache.py:2079\u001B[39m, in \u001B[36m_worker_compile_cpp\u001B[39m\u001B[34m(lock_path, cpp_builder)\u001B[39m\n\u001B[32m   2077\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m FileLock(lock_path, timeout=LOCK_TIMEOUT):\n\u001B[32m   2078\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(cpp_builder.get_target_file_path()):\n\u001B[32m-> \u001B[39m\u001B[32m2079\u001B[39m         cpp_builder.build()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:1601\u001B[39m, in \u001B[36mCppBuilder.build\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1598\u001B[39m _create_if_dir_not_exist(_build_tmp_dir)\n\u001B[32m   1600\u001B[39m build_cmd = \u001B[38;5;28mself\u001B[39m.get_command_line()\n\u001B[32m-> \u001B[39m\u001B[32m1601\u001B[39m run_compile_cmd(build_cmd, cwd=_build_tmp_dir)\n\u001B[32m   1602\u001B[39m _remove_dir(_build_tmp_dir)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:355\u001B[39m, in \u001B[36mrun_compile_cmd\u001B[39m\u001B[34m(cmd_line, cwd)\u001B[39m\n\u001B[32m    353\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_compile_cmd\u001B[39m(cmd_line: \u001B[38;5;28mstr\u001B[39m, cwd: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    354\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m dynamo_timed(\u001B[33m\"\u001B[39m\u001B[33mcompile_file\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m355\u001B[39m         _run_compile_cmd(cmd_line, cwd)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/torch/_inductor/cpp_builder.py:350\u001B[39m, in \u001B[36m_run_compile_cmd\u001B[39m\u001B[34m(cmd_line, cwd)\u001B[39m\n\u001B[32m    340\u001B[39m     instruction = (\n\u001B[32m    341\u001B[39m         \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mOpenMP support not found. Please try one of the following solutions:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    342\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m(1) Set the `CXX` environment variable to a compiler other than Apple clang++/g++ \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    347\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m with `include/omp.h` under it.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    348\u001B[39m     )\n\u001B[32m    349\u001B[39m     output += instruction\n\u001B[32m--> \u001B[39m\u001B[32m350\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc.CppCompileError(cmd, output) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mInductorError\u001B[39m: CppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp -D TORCH_INDUCTOR_CPP_WRAPPER -D STANDALONE_TORCH_HEADER -D C10_USING_CUSTOM_GENERATED_MACROS -D CPU_CAPABILITY_AVX2 -shared -fPIC -O3 -DNDEBUG -fno-trapping-math -funsafe-math-optimizations -ffinite-math-only -fno-signed-zeros -fno-math-errno -fexcess-precision=fast -fno-finite-math-only -fno-unsafe-math-optimizations -ffp-contract=off -fno-tree-loop-vectorize -march=native -Wall -std=c++17 -Wno-unused-variable -Wno-unknown-pragmas -fopenmp -I/home/alexandr/miniconda3/include/python3.12 -I/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/include -I/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -mavx2 -mfma -mf16c -D_GLIBCXX_USE_CXX11_ABI=1 -ltorch -ltorch_cpu -ltorch_python -lgomp -L/home/alexandr/miniconda3/lib -L/home/alexandr/miniconda3/lib/python3.12/site-packages/torch/lib -o /tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.so\n\nOutput:\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp: In function 'void kernel(const int64_t*, const float*, const float*, const float*, const float*, const float*, const float*, float*, float*)':\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp:29:23: error: redeclaration of 'float tmp_acc0_arr [8]'\n   29 |                 float tmp_acc0_arr[8];\n      |                       ^~~~~~~~~~~~\n/tmp/torchinductor_alexandr/mh/cmhvw2g25ue5wt335rhkxurdtvuworah5ayxwbe6vgbffpjgkmue.cpp:17:23: note: 'float tmp_acc0_arr [8]' previously declared here\n   17 |                 float tmp_acc0_arr[8];\n      |                       ^~~~~~~~~~~~\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "# Оцениваем точность на проверенном наборе val_data\n",
    "eval_results = trainer.evaluate()\n",
    "print(f'Точность в наборе для проверки: {eval_results[\"eval_accuracy\"]:.3f}')"
   ],
   "metadata": {
    "id": "wtPxahsKCufH",
    "ExecuteTime": {
     "end_time": "2025-05-03T12:26:14.706809Z",
     "start_time": "2025-05-03T12:24:56.543632Z"
    }
   },
   "outputs": [],
   "execution_count": null,
   "id": "5ef8619634c3a7bf"
  },
  {
   "cell_type": "code",
   "source": [
    "# Написание функции для получения предикта\n",
    "def get_prediction():\n",
    "    test_pred = trainer.predict(tokenized_dataset['test'])\n",
    "    labels = np.argmax(test_pred.predictions, axis=-1)\n",
    "    return labels\n",
    "\n",
    "\n",
    "pred = get_prediction()"
   ],
   "metadata": {
    "id": "ft6SVqlYGDSl",
    "ExecuteTime": {
     "end_time": "2025-05-03T12:27:03.061318Z",
     "start_time": "2025-05-03T12:26:14.792722Z"
    }
   },
   "outputs": [],
   "execution_count": null,
   "id": "9d454a735e72deb1"
  },
  {
   "cell_type": "code",
   "source": [
    "# Проверка полученного результата\n",
    "print(classification_report(tokenized_dataset['test'], pred))\n",
    "print(f1_score(tokenized_dataset['test'], pred))"
   ],
   "metadata": {
    "id": "enl7pfFYGQVG",
    "ExecuteTime": {
     "end_time": "2025-05-03T12:27:03.179591Z",
     "start_time": "2025-05-03T12:27:03.130706Z"
    }
   },
   "outputs": [],
   "execution_count": null,
   "id": "2845fa49ff2b223c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:27:04.597241Z",
     "start_time": "2025-05-03T12:27:03.356775Z"
    },
    "id": "xpGsUvaN1Cs4"
   },
   "cell_type": "code",
   "source": [
    "# Сохранение обученной модели\n",
    "model_path = BASE_DIR + '/fine-tune-RuBert'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "bb059704c75ca96d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:40:38.102529Z",
     "start_time": "2025-05-03T12:40:38.072273Z"
    },
    "id": "Ik3GObOK1Cs6"
   },
   "cell_type": "code",
   "source": [
    "data_pred = test_data.copy()\n",
    "data_pred['pred'] = pred\n",
    "data_pred"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "418c5cc535770d5f"
  },
  {
   "metadata": {
    "id": "S8uEiju01Cs9"
   },
   "cell_type": "markdown",
   "source": [
    "Результат получился неплохим f1=0.863, данную модель можно улучшить подбирая гиперпараметры."
   ],
   "id": "53e622dc2d6d8bd6"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1eIEblWTtVI_inFFzUJgWIJ2-LWDLYj6a",
     "timestamp": 1746441578625
    },
    {
     "file_id": "https://github.com/AlexandrGor13/nlp_homework/blob/master/homework3/homework3_RuBERT.ipynb",
     "timestamp": 1746421450629
    }
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5145169b4dea4e288768f1734de4ed64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b0a7d3f569e84773926c00f0a7909720",
       "IPY_MODEL_06fe444b7b8c474fa7eb19bea866d499",
       "IPY_MODEL_b84536dfd02449409c4177c90baa59e0"
      ],
      "layout": "IPY_MODEL_edf219077c5b45dca3ed970e5a85225e"
     }
    },
    "b0a7d3f569e84773926c00f0a7909720": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a257615ec5c4ce4b57db9b87c3cf16c",
      "placeholder": "​",
      "style": "IPY_MODEL_d993f8fa5dea42f6b5b25a18ece0f377",
      "value": "Map: 100%"
     }
    },
    "06fe444b7b8c474fa7eb19bea866d499": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c433e32fe5a4cd792a219404c26a9a3",
      "max": 6295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7ac4a47bcba4dfab8cb897da243774f",
      "value": 6295
     }
    },
    "b84536dfd02449409c4177c90baa59e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8364a257e72432c80ba052eb2528c67",
      "placeholder": "​",
      "style": "IPY_MODEL_ebcd53f4ab814261a9c6fd7cc56eeeca",
      "value": " 6295/6295 [00:01&lt;00:00, 4368.36 examples/s]"
     }
    },
    "edf219077c5b45dca3ed970e5a85225e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a257615ec5c4ce4b57db9b87c3cf16c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d993f8fa5dea42f6b5b25a18ece0f377": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c433e32fe5a4cd792a219404c26a9a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7ac4a47bcba4dfab8cb897da243774f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8364a257e72432c80ba052eb2528c67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebcd53f4ab814261a9c6fd7cc56eeeca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb78fe3296554aa3852491cc538e40c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbb27a27918049d98dddb7e89944a2ab",
       "IPY_MODEL_7bce20acefb343899893cbb6f9279a08",
       "IPY_MODEL_09ffb6acf8f64c04a4606b36ec9e8dac"
      ],
      "layout": "IPY_MODEL_0d9ce94250c34d37a7e6428f4291084b"
     }
    },
    "fbb27a27918049d98dddb7e89944a2ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22db009dc58845f88e62599dd5134b86",
      "placeholder": "​",
      "style": "IPY_MODEL_0c166149796741ddb8a281d47a5ef242",
      "value": "Map: 100%"
     }
    },
    "7bce20acefb343899893cbb6f9279a08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_717939ee14794130a3631f7806479ce9",
      "max": 1574,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_389822ab292e407f97bf77dfaa1fc82f",
      "value": 1574
     }
    },
    "09ffb6acf8f64c04a4606b36ec9e8dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8feeab83c76e4cdc8f03e7ca3241c74e",
      "placeholder": "​",
      "style": "IPY_MODEL_c26629a7160946cfb13b67fe5356b9a6",
      "value": " 1574/1574 [00:00&lt;00:00, 4102.00 examples/s]"
     }
    },
    "0d9ce94250c34d37a7e6428f4291084b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22db009dc58845f88e62599dd5134b86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c166149796741ddb8a281d47a5ef242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "717939ee14794130a3631f7806479ce9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "389822ab292e407f97bf77dfaa1fc82f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8feeab83c76e4cdc8f03e7ca3241c74e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c26629a7160946cfb13b67fe5356b9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39c2e70f46914e0d80d2c5f7b4db149c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6c0825659254364bf33055f48ce80b7",
       "IPY_MODEL_e774ea85cb534a7b9f9e12bcd54efd56",
       "IPY_MODEL_41838afe34444d21b803cc9b903acf99"
      ],
      "layout": "IPY_MODEL_7a46842553624888a41313cb05cca0a6"
     }
    },
    "a6c0825659254364bf33055f48ce80b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f3c652c5c1a41fd96c2d41d2f273b74",
      "placeholder": "​",
      "style": "IPY_MODEL_08a3ac5214824cd5838749ed0ea79c9f",
      "value": "Map: 100%"
     }
    },
    "e774ea85cb534a7b9f9e12bcd54efd56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c9ef60d41a04a12b3f7cb1a1c4e05c7",
      "max": 983,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24b1c88ee3b7414cb1362189c7a80af8",
      "value": 983
     }
    },
    "41838afe34444d21b803cc9b903acf99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3ef5939a9ed46c7b8e48d77a08844ee",
      "placeholder": "​",
      "style": "IPY_MODEL_8aabea2129a74e379ab9a4e5975dfead",
      "value": " 983/983 [00:00&lt;00:00, 3971.14 examples/s]"
     }
    },
    "7a46842553624888a41313cb05cca0a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f3c652c5c1a41fd96c2d41d2f273b74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08a3ac5214824cd5838749ed0ea79c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c9ef60d41a04a12b3f7cb1a1c4e05c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24b1c88ee3b7414cb1362189c7a80af8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3ef5939a9ed46c7b8e48d77a08844ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aabea2129a74e379ab9a4e5975dfead": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
